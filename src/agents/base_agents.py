from agents import Agent, Runner, OpenAIChatCompletionsModel
from constants import clients
from typing import Type, List
from src.utils.code_model import CodeItem
from src.utils.json_utils import safe_json_loads

################# Base Agent #############################################
class BaseCodeAgent:
    """
    Represents an agent that utilizes a specified model to process input text.
    
    Attributes:
        model_name (str): The name of the model used by the agent.
        agent (Agent): The agent instance configured with the provided parameters.
    
    Args:
        name (str): The name of the agent.
        system_prompt (str): The prompt that guides the agent's behavior.
        model_name (str, optional): The model to use for the agent. Defaults to 'gpt-4o-mini'.
    
    Raises:
        ValueError: If the model_name is not found in the clients dictionary.
    """
    def __init__(self, name: str, system_prompt: str, model_name: str = "gpt-4o-mini"):
        """
        Initializes the BaseCodeAgent with a specified name, system prompt, and model name.
        
        Args:
            name (str): The name of the agent.
            system_prompt (str): The prompt that guides the agent's behavior.
            model_name (str, optional): The model to use for the agent. Defaults to 'gpt-4o-mini'.
        
        Raises:
            ValueError: If the model_name is not found in the clients dictionary.
        """
        if model_name not in clients:
            raise ValueError(f"Model '{model_name}' not found in clients dictionary.")

        self.model_name = model_name

        client = clients[model_name]
        model_obj = OpenAIChatCompletionsModel(model=model_name, openai_client=client)

        self.agent = Agent(
            name=name,
            instructions=system_prompt,
            output_type=str,
            model=model_obj,
        )

    async def run(self, input_text: str) -> str:
        """
        Executes the agent's functionality with the provided input text and returns the result.
        
        Args:
            input_text (str): The text input to be processed by the agent.
        
        Returns:
            str: The final output generated by the agent after processing the input.
        """
        result = await Runner.run(self.agent, input_text)
        return result.final_output


################## Base generating code agent ###########################


class BaseCodeGenerationAgent(BaseCodeAgent):
    """
    Base agent for generating structured code outputs (docstrings, tests, etc.)
    """
    OutputModel: Type  # to be set in subclasses
    SYSTEM_PROMPT: str
    PROMPT_TEMPLATE: str

    def __init__(self, model_name: str):
        super().__init__(name=self.__class__.__name__, system_prompt=self.SYSTEM_PROMPT, model_name=model_name)
        self.agent.output_type = list[self.OutputModel]

    def _make_prompt(self, items: List[CodeItem]) -> str:
        all_imports = set()
        for item in items:
            all_imports.update(getattr(item, "imports", []))
        imports_code = "\n".join(all_imports)
        formatted_items = [
            f"# File: {item.file_path}\n# {item.type} {item.name}\n{item.source}"
            for item in items
        ]
        items_code = "\n\n".join(formatted_items)
        return self.PROMPT_TEMPLATE + "\n" + imports_code + "\n\n" + items_code

    async def generate(self, items: List[CodeItem]) -> List:
        prompt = self._make_prompt(items)
        try:
            result = await self.run(prompt)
        except Exception as e:
            print(f"⚠️ Error generating {self.__class__.__name__} output — using manual fallback")
            print("Details:", e)
            self.agent.output_type = str
            result_text = await self.run(prompt)
            parsed = safe_json_loads(result_text)
            if not parsed:
                return []
            return [self.OutputModel(**d) for d in parsed]

        if isinstance(result, str):
            parsed = safe_json_loads(result)
            if not parsed:
                return []
            return [self.OutputModel(**d) for d in parsed]

        return result
