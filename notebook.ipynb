{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4d44af",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "0d5ae87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API KEYS\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "# API Urls compatibles wit openai\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# Client instances\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "groq_client = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "\n",
    "# Clients models and client dictionary\n",
    "models = [\"gpt-4o-mini\",\n",
    "          \"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "          \"openai/gpt-oss-20b\",\n",
    "          \"openai/gpt-oss-120b\" ]\n",
    "\n",
    "clients = {\n",
    "    \"gpt-4o-mini\": openai_client,                                   # OpenAI model                $0.15/$0.60\n",
    "    \"meta-llama/llama-4-scout-17b-16e-instruct\" : groq_client,      # Groq Llama model            $0.11/$0.34\n",
    "    \"openai/gpt-oss-20b\": groq_client,                              # Groq GPT OSS 20B - cheaper  $0.075/$0.30\n",
    "    \"openai/gpt-oss-120b\": groq_client                              # Groq GPT OSS 120B powerful  $0.15/$0.60\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "e2ab1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Python expert. Analyze Python functions and improve documentation.\n",
    "- Generate or improve Python docstrings following best practices updated in 2025:\n",
    "  - Include a brief description of what the function does.\n",
    "  - Include Args with type annotations and descriptions.\n",
    "  - Include Returns with type and description if applicable.\n",
    "  - Include Raises ONLY if the function can raise exceptions.\n",
    "  - If the function doensn't return anything, don't include the return secton. \n",
    "  - Keep lines <= 79 characters.\n",
    "- ONLY return a valid JSON array (list of dictionaries). Each string must be enclosed\n",
    "  in a single pair of double quotes. Use '\\n' for line breaks inside strings.\n",
    "- Correct any formatting errors in existing docstrings.\n",
    "- Do NOT add explanations, code, or anything else outside the JSON.\n",
    "- Do NOT use Markdown syntax (no ```python).\n",
    "- Write all text in English.\n",
    "- If there is nothing to improve, return the original docstring.\n",
    "- Each dictionary must have keys:\n",
    "  - \"name\": function name\n",
    "  - \"docstring\": improved or generated docstring (without triple quotes)\n",
    "- Do not break strings into multiple quoted segments.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_BASE = \"\"\"\n",
    "Generate or improve Python docstrings for the following functions.\n",
    "Return a JSON array (list of dicts), each dict with keys:\n",
    "- \"name\": function name\n",
    "- \"docstring\": improved or generated docstring (without triple quotes)\n",
    "\n",
    "Functions:\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d70559",
   "metadata": {},
   "source": [
    "# STEP 1: Extract the functions info from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "8fa3e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "#############################################################################\n",
    "# Function to extract the info of the functons from the path of a python file \n",
    "#############################################################################\n",
    "\n",
    "def extract_functions(file_path):\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    # Parse the code into an Abstract Syntax Tree (AST)\n",
    "    tree = ast.parse(code)\n",
    "\n",
    "    funcs = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            # Extract data of each function\n",
    "            func_info = {\n",
    "                \"name\": node.name,\n",
    "                \"args\": [arg.arg for arg in node.args.args],\n",
    "                \"docstring\": ast.get_docstring(node),\n",
    "                \"source\": ast.get_source_segment(code, node)\n",
    "            }\n",
    "            funcs.append(func_info)\n",
    "\n",
    "    return funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "24441921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Name: greet\n",
      "   Arguments: ['name']\n",
      "   Docstring: Return a friendly greeting for the given name.\n",
      "\n",
      "Args:\n",
      "    name (str): The name of the person to greet.\n",
      "\n",
      "Returns:\n",
      "    str: A greeting message containing the given name.\n",
      "   Source: def greet(name):\n",
      "    \"\"\"\n",
      "    Return a friendly greeting for the given name.\n",
      "    \n",
      "    Args:\n",
      "        name (str): The name of the person to greet.\n",
      "    \n",
      "    Returns:\n",
      "        str: A greeting message containing the given name.\n",
      "    \"\"\"\n",
      "    return f'Hello, {name}!'\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ”¹ Name: add\n",
      "   Arguments: ['a', 'b']\n",
      "   Docstring: Return the sum of two numeric values.\n",
      "\n",
      "Args:\n",
      "    a (int | float): The first value to add.\n",
      "    b (int | float): The second value to add.\n",
      "\n",
      "Returns:\n",
      "    int | float: The sum of a and b.\n",
      "   Source: def add(a, b):\n",
      "    \"\"\"\n",
      "    Return the sum of two numeric values.\n",
      "    \n",
      "    Args:\n",
      "        a (int | float): The first value to add.\n",
      "        b (int | float): The second value to add.\n",
      "    \n",
      "    Returns:\n",
      "        int | float: The sum of a and b.\n",
      "    \"\"\"\n",
      "    return a + b\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ”¹ Name: multiply\n",
      "   Arguments: ['a', 'b', 'c']\n",
      "   Docstring:  \n",
      "    \n",
      "   Source: def multiply(a, b, c=1):\n",
      "    \"\"\"\n",
      " \n",
      "    \"\"\"\n",
      "    return a * b * c\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"examples/example.py\" \n",
    "\n",
    "functions = extract_functions(file_path)\n",
    "\n",
    "for func in functions:\n",
    "    print(f\"\\nðŸ”¹ Name: {func['name']}\")\n",
    "    print(f\"   Arguments: {func['args']}\")\n",
    "    print(f\"   Docstring: {func['docstring']}\")\n",
    "    print(f\"   Source: {func['source']}\")\n",
    "\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b329d4a",
   "metadata": {},
   "source": [
    "# STEP 2: Generate docstrings with openai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "9f48d9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'greet',\n",
       "  'args': ['name'],\n",
       "  'docstring': 'Return a friendly greeting for the given name.\\n\\nArgs:\\n    name (str): The name of the person to greet.\\n\\nReturns:\\n    str: A greeting message containing the given name.',\n",
       "  'source': 'def greet(name):\\n    \"\"\"\\n    Return a friendly greeting for the given name.\\n    \\n    Args:\\n        name (str): The name of the person to greet.\\n    \\n    Returns:\\n        str: A greeting message containing the given name.\\n    \"\"\"\\n    return f\\'Hello, {name}!\\''},\n",
       " {'name': 'add',\n",
       "  'args': ['a', 'b'],\n",
       "  'docstring': 'Return the sum of two numeric values.\\n\\nArgs:\\n    a (int | float): The first value to add.\\n    b (int | float): The second value to add.\\n\\nReturns:\\n    int | float: The sum of a and b.',\n",
       "  'source': 'def add(a, b):\\n    \"\"\"\\n    Return the sum of two numeric values.\\n    \\n    Args:\\n        a (int | float): The first value to add.\\n        b (int | float): The second value to add.\\n    \\n    Returns:\\n        int | float: The sum of a and b.\\n    \"\"\"\\n    return a + b'},\n",
       " {'name': 'multiply',\n",
       "  'args': ['a', 'b', 'c'],\n",
       "  'docstring': ' \\n    ',\n",
       "  'source': 'def multiply(a, b, c=1):\\n    \"\"\"\\n \\n    \"\"\"\\n    return a * b * c'}]"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "66c86e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(prompt_base, functions):\n",
    "  functions_code = \"\\n\\n\".join([f['source'] for f in functions])\n",
    "  prompt = prompt_base + functions_code\n",
    "\n",
    "  return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "8be9e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate or improve Python docstrings for the following functions.\n",
      "Return a JSON array (list of dicts), each dict with keys:\n",
      "- \"name\": function name\n",
      "- \"docstring\": improved or generated docstring (without triple quotes)\n",
      "\n",
      "Functions:\n",
      "\n",
      "def greet(name):\n",
      "    \"\"\"\n",
      "    Return a friendly greeting for the given name.\n",
      "    \n",
      "    Args:\n",
      "        name (str): The name of the person to greet.\n",
      "    \n",
      "    Returns:\n",
      "        str: A greeting message containing the given name.\n",
      "    \"\"\"\n",
      "    return f'Hello, {name}!'\n",
      "\n",
      "def add(a, b):\n",
      "    \"\"\"\n",
      "    Return the sum of two numeric values.\n",
      "    \n",
      "    Args:\n",
      "        a (int | float): The first value to add.\n",
      "        b (int | float): The second value to add.\n",
      "    \n",
      "    Returns:\n",
      "        int | float: The sum of a and b.\n",
      "    \"\"\"\n",
      "    return a + b\n",
      "\n",
      "def multiply(a, b, c=1):\n",
      "    \"\"\"\n",
      " \n",
      "    \"\"\"\n",
      "    return a * b * c\n"
     ]
    }
   ],
   "source": [
    "print(make_prompt(PROMPT_BASE, functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "446c43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def generate_docstrings(functions, prompt_base, system_prompt=None, model=\"openai/gpt-oss-20b\"):\n",
    "    \"\"\"\n",
    "    Generate docstrings for multiple functions in a single LLM call.\n",
    "\n",
    "    Args:\n",
    "        functions: list of dicts with keys 'name' and 'source'\n",
    "        model: str, model name to use\n",
    "\n",
    "    Returns:\n",
    "        list of dicts with keys 'name' and 'docstring'\n",
    "    \"\"\"\n",
    "    prompt = make_prompt(prompt_base, functions)\n",
    "    \n",
    "    if model not in clients:\n",
    "        raise ValueError(f\"Model '{model}' not found in clients dictionary.\")\n",
    "    client = clients[model]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=2000, \n",
    "        response_format={\"type\": \"text\"}\n",
    "    )\n",
    "    print(\"DEBUG: response:\", response)\n",
    "    raw_text = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        # Convierte el JSON generado por el modelo en una lista de dicts de Python\n",
    "        return json.loads(raw_text)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON from model output:\", e)\n",
    "        print(\"Raw output was:\")\n",
    "        print(response.choices[0].message.content)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "76518771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: response: ChatCompletion(id='chatcmpl-9c6c7c13-53dd-4969-9430-7e2adc40e5a2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='[\\n  {\\n    \"name\": \"greet\",\\n    \"docstring\": \"Return a friendly greeting for the given name.\\\\n\\\\nArgs:\\\\n    name (str): The name of the person to greet.\\\\n\\\\nReturns:\\\\n    str: A greeting message containing the given name.\"\\n  },\\n  {\\n    \"name\": \"add\",\\n    \"docstring\": \"Return the sum of two numeric values.\\\\n\\\\nArgs:\\\\n    a (int, float): The first value to add.\\\\n    b (int, float): The second value to add.\\\\n\\\\nReturns:\\\\n    int, float: The sum of a and b.\"\\n  },\\n  {\\n    \"name\": \"multiply\",\\n    \"docstring\": \"Return the product of two or three numeric values.\\\\n\\\\nArgs:\\\\n    a (int, float): The first multiplier.\\\\n    b (int, float): The second multiplier.\\\\n    c (int, float, optional): The optional third multiplier. Defaults to 1.\\\\n\\\\nReturns:\\\\n    int, float: The product of a, b, and c.\"\\n  }\\n]', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning='We need to output JSON array with dictionaries for each function. We need to generate or improve docstrings. They should follow best practices updated in 2025.\\n\\nCheck each function:\\n\\ngreet: docstring currently good but we need to ensure line lengths <= 79. It has two lines after Args? It\\'s fine.\\n\\nWe need to ensure type annotations in Args: they already have. But the docstring format: It might need to show \"int | float\" vs \"int or float\"? In 2025, type annotations in docstrings should be \"int, float\" separated by commas. The example uses \"int | float\". But maybe we keep the same style? We should keep as \"int, float\". Also need to include a brief description of what function does: \"Return a friendly greeting for the given name.\" That\\'s fine. The Args section: \"name (str): The name of the person to greet.\" Good. Returns: \"str: A greeting message containing the given name.\" Good.\\n\\nWe should keep lines <= 79. The description line length: \"Return a friendly greeting for the given name.\" length 44. Good. The Args line length: \"name (str): The name of the person to greet.\" length 43. Good. Returns line: \"str: A greeting message containing the given name.\" length 53. Good.\\n\\nSo we keep docstring as is.\\n\\nFor add: same: \"Return the sum of two numeric values.\" line length 33. Args: \"a (int | float): The first value to add.\" length 44. But \"int | float\" may exceed? It\\'s fine. But we should use \"int, float\" style. Let\\'s convert.\\n\\nAlso Returns: \"int | float: The sum of a and b.\" Should use \"int, float\". So improved docstring:\\n\\n\"\"\"\\nReturn the sum of two numeric values.\\n\\nArgs:\\n    a (int, float): The first value to add.\\n    b (int, float): The second value to add.\\n\\nReturns:\\n    int, float: The sum of a and b.\\n\"\"\"\\n\\nNeed to keep lines <= 79: All okay.\\n\\nFor multiply: The current docstring is empty. We need to generate docstring.\\n\\nParameters: a, b, c=1. Type: int or float. The function returns product of a, b, c. So:\\n\\n\"\"\"\\nReturn the product of two or three numeric values.\\n\\nArgs:\\n    a (int, float): The first multiplier.\\n    b (int, float): The second multiplier.\\n    c (int, float, optional): The optional third multiplier. Defaults to 1.\\n\\nReturns:\\n    int, float: The product of a, b, and c.\\n\"\"\"\\n\\nCheck line lengths: \"Return the product of two or three numeric values.\" length 47. Good. Args lines: \"a (int, float): The first multiplier.\" length 40. \"b (int, float): The second multiplier.\" length 40. \"c (int, float, optional): The optional third multiplier. Defaults to 1.\" length 73. Good. Returns line length: \"int, float: The product of a, b, and c.\" length 48. Good.\\n\\nAlso include Raises? None.\\n\\nNow we need to produce JSON array with dictionaries, each string inside single quotes? Actually they say \"Each string must be enclosed in a single pair of double quotes.\" Use \\' \\' for line breaks inside strings. So inside JSON, the docstring string must contain line breaks as actual newline characters, not \\\\n? They say use \\'\\\\n\\' for line breaks inside strings. That means each string must include \\\\n characters. Also each string must be enclosed in a single pair of double quotes.\\n\\nSo each dict:\\n\\n{\\n  \"name\": \"greet\",\\n  \"docstring\": \"Return a friendly greeting for the given name.\\\\n\\\\nArgs:\\\\n    name (str): The name of the person to greet.\\\\n\\\\nReturns:\\\\n    str: A greeting message containing the given name.\"\\n}\\n\\nNote that we need to escape newlines with \\\\n. Also keep indentation spaces. The example uses 4 spaces indentation inside docstring lines. We\\'ll replicate.\\n\\nCheck length <= 79 per line? For lines inside string we must consider they are part of string, but actual lines? The string will have newline characters; the lines after newline will have indentation spaces and the content. We should ensure each line not exceed 79 characters. Let\\'s check each line in the string.\\n\\nFor greet:\\nLine1: \"Return a friendly greeting for the given name.\" length 44.\\nLine2: \"\" (empty). length 0.\\nLine3: \"Args:\" length 5.\\nLine4: \"    name (str): The name of the person to greet.\" length: 44.\\nLine5: \"\" length 0.\\nLine6: \"Returns:\" length 8.\\nLine7: \"    str: A greeting message containing the given name.\" length: 53.\\n\\nAll good.\\n\\nFor add:\\nLine1: \"Return the sum of two numeric values.\" length 33.\\nLine2: \"\".\\nLine3: \"Args:\" length 5.\\nLine4: \"    a (int, float): The first value to add.\" length: 44.\\nLine5: \"    b (int, float): The second value to add.\" length: 44.\\nLine6: \"\".\\nLine7: \"Returns:\" length 8.\\nLine8: \"    int, float: The sum of a and b.\" length: 33.\\n\\nAll good.\\n\\nFor multiply:\\nLine1: \"Return the product of two or three numeric values.\" length 47.\\nLine2: \"\".\\nLine3: \"Args:\" length 5.\\nLine4: \"    a (int, float): The first multiplier.\" length 40.\\nLine5: \"    b (int, float): The second multiplier.\" length 40.\\nLine6: \"    c (int, float, optional): The optional third multiplier. Defaults to 1.\" length 73.\\nLine7: \"\".\\nLine8: \"Returns:\" length 8.\\nLine9: \"    int, float: The product of a, b, and c.\" length 48.\\n\\nAll good.\\n\\nNow we need to output a JSON array list of dicts in the required format. No explanations. No extra characters. Output must be JSON, not inside triple quotes. Each dict keys must be \"name\" and \"docstring\" without quotes inside value? The value is a string with quotes.\\n\\nMake sure we escape double quotes inside string? There\\'s no double quotes inside docstring, so fine.\\n\\nLet\\'s produce final.'))], created=1761583257, model='openai/gpt-oss-20b', object='chat.completion', service_tier='on_demand', system_fingerprint='fp_04b2b9f7fa', usage=CompletionUsage(completion_tokens=1613, prompt_tokens=514, total_tokens=2127, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.044978181, prompt_time=0.026508375, completion_time=1.631511697, total_time=1.658020072), usage_breakdown=None, x_groq={'id': 'req_01k8k8pm24f7gv7c86gvhexx2v'})\n"
     ]
    }
   ],
   "source": [
    "suggested_docstrings = generate_docstrings(\n",
    "    functions=functions, \n",
    "    model=\"openai/gpt-oss-20b\", \n",
    "    prompt_base=PROMPT_BASE,\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "ee5efdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'greet',\n",
       "  'docstring': 'Return a friendly greeting for the given name.\\n\\nArgs:\\n    name (str): The name of the person to greet.\\n\\nReturns:\\n    str: A greeting message containing the given name.'},\n",
       " {'name': 'add',\n",
       "  'docstring': 'Return the sum of two numeric values.\\n\\nArgs:\\n    a (int, float): The first value to add.\\n    b (int, float): The second value to add.\\n\\nReturns:\\n    int, float: The sum of a and b.'},\n",
       " {'name': 'multiply',\n",
       "  'docstring': 'Return the product of two or three numeric values.\\n\\nArgs:\\n    a (int, float): The first multiplier.\\n    b (int, float): The second multiplier.\\n    c (int, float, optional): The optional third multiplier. Defaults to 1.\\n\\nReturns:\\n    int, float: The product of a, b, and c.'}]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggested_docstrings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d531e",
   "metadata": {},
   "source": [
    "# STEP 3: Write docstring in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "15b90b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "def update_docstring(file_path, func_data):\n",
    "    \"\"\"\n",
    "    Update or insert docstrings for specific functions in a Python file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str | Path): Path to the Python file.\n",
    "        func_data (dict): Dictionary with:\n",
    "            - \"name\": function name.\n",
    "            - \"docstring\": new docstring (string with \\n for line breaks).\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    lines = file_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "    source = \"\\n\".join(lines)\n",
    "    tree = ast.parse(source)\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef) and node.name == func_data[\"name\"]:\n",
    "            # --- Compute indentation ---\n",
    "            func_indent = len(lines[node.lineno - 1]) - len(lines[node.lineno - 1].lstrip())\n",
    "            body_indent = \" \" * (func_indent + 4)\n",
    "\n",
    "            # --- Prepare the new docstring block ---\n",
    "            doc_lines = func_data[\"docstring\"].split(\"\\n\")\n",
    "            new_doc_block = (\n",
    "                [body_indent + '\"\"\"']\n",
    "                + [body_indent + line for line in doc_lines]\n",
    "                + [body_indent + '\"\"\"']\n",
    "            )\n",
    "\n",
    "            # --- If function already has a docstring, replace it ---\n",
    "            if (\n",
    "                node.body\n",
    "                and isinstance(node.body[0], ast.Expr)\n",
    "                and isinstance(getattr(node.body[0], \"value\", None), ast.Constant)\n",
    "                and isinstance(node.body[0].value.value, str)\n",
    "            ):\n",
    "                doc_start_idx = node.body[0].lineno - 1\n",
    "\n",
    "                # Find where the existing triple quotes end\n",
    "                doc_end_idx = doc_start_idx + 1\n",
    "                open_quote = None\n",
    "                if lines[doc_start_idx].strip().startswith('\"\"\"'):\n",
    "                    open_quote = '\"\"\"'\n",
    "                elif lines[doc_start_idx].strip().startswith(\"'''\"):\n",
    "                    open_quote = \"'''\"\n",
    "\n",
    "                while doc_end_idx < len(lines):\n",
    "                    if lines[doc_end_idx].strip().endswith(open_quote):\n",
    "                        doc_end_idx += 1\n",
    "                        break\n",
    "                    doc_end_idx += 1\n",
    "\n",
    "                # Replace the old docstring block\n",
    "                lines[doc_start_idx:doc_end_idx] = new_doc_block\n",
    "\n",
    "            else:\n",
    "                # --- No existing docstring: insert it right after def line ---\n",
    "                insert_idx = node.body[0].lineno - 1\n",
    "                lines[insert_idx:insert_idx] = new_doc_block\n",
    "\n",
    "    # --- Save the modified file ---\n",
    "    file_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "1108b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for func in suggested_docstrings:\n",
    "  update_docstring(file_path, func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f0a91",
   "metadata": {},
   "source": [
    "# MORE COMPLEX FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "a543a891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4o-mini',\n",
       " 'meta-llama/llama-4-scout-17b-16e-instruct',\n",
       " 'openai/gpt-oss-20b',\n",
       " 'openai/gpt-oss-120b']"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "fceac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_0 = \"examples/train_engine.py\"\n",
    "functions = extract_functions(file_path_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "1ba4251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: response: ChatCompletion(id='chatcmpl-CVKXGECUOCdZwnCudT3QEGBbq54tK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='[\\n    {\\n        \"name\": \"train_step\",\\n        \"docstring\": \"Perform a single training epoch over the provided dataloader. It updates the model parameters via backpropagation, computes the average loss, and evaluates the specified metrics. Returns a dictionary mapping metric names to their computed values, including the average loss.\\\\n\\\\nArgs:\\\\n    model (torch.nn.Module): The model to train.\\\\n    dataloader (DataLoader): DataLoader yielding input tensors and target labels.\\\\n    loss_fn (callable): Callable that computes the loss between model outputs and targets.\\\\n    optimizer (torch.optim.Optimizer): Optimizer used to update the model.\\\\n    device (torch.device): Device on which computations occur.\\\\n    metrics_list (list, optional): List of metric names to compute; defaults to [\\'accuracy\\']. \\\\n\\\\nReturns:\\\\n    dict: Metric names mapped to their computed float values.\\\\n\\\\nRaises:\\\\n    RuntimeError: If there is an error during the training step.\"\\n    },\\n    {\\n        \"name\": \"train_mlflow\",\\n        \"docstring\": \"Train a model with MLflow tracking.\\\\n\\\\nArgs:\\\\n    model (torch.nn.Module): The model to train.\\\\n    train_loader (DataLoader): DataLoader yielding input tensors and target labels for training.\\\\n    val_loader (DataLoader): DataLoader yielding input tensors and target labels for validation.\\\\n    optimizer (torch.optim.Optimizer): Optimizer used to update the model.\\\\n    loss_fn (callable): Callable that computes the loss between model outputs and targets.\\\\n    cfg (dict): Configuration dictionary.\\\\n    device (torch.device, optional): Device on which computations occur; defaults to None.\\\\n    continue_training (bool, optional): Whether to continue training from a previous checkpoint; defaults to False.\\\\n    continue_path (str, optional): Path to the previous checkpoint; defaults to None.\\\\n    prev_metrics (dict, optional): Previous metrics; defaults to None.\\\\n\\\\nReturns:\\\\n    dict: Training results.\"\\n    },\\n    {\\n        \"name\": \"__init__\",\\n        \"docstring\": \"Initializes an EarlyStopping monitor that stops training when a monitored metric does not improve for a specified number of epochs.\\\\n\\\\nArgs:\\\\n    patience (int): Number of epochs with no improvement to tolerate.\\\\n    verbose (bool): Whether to print messages when no improvement is observed.\\\\n    delta (float): Minimum change to qualify as an improvement.\"\\n    },\\n    {\\n        \"name\": \"__call__\",\\n        \"docstring\": \"Call the EarlyStopping monitor.\\\\n\\\\nArgs:\\\\n    val_loss (float): Validation loss.\"\\n    }\\n]', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761583142, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=553, prompt_tokens=2339, total_tokens=2892, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "suggested = generate_docstrings(\n",
    "    functions=functions, \n",
    "    model=\"gpt-4o-mini\", \n",
    "    prompt_base=PROMPT_BASE,\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "dc8b4808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'train_step',\n",
       "  'docstring': \"Perform a single training epoch over the provided dataloader. It updates the model parameters via backpropagation, computes the average loss, and evaluates the specified metrics. Returns a dictionary mapping metric names to their computed values, including the average loss.\\n\\nArgs:\\n    model (torch.nn.Module): The model to train.\\n    dataloader (DataLoader): DataLoader yielding input tensors and target labels.\\n    loss_fn (callable): Callable that computes the loss between model outputs and targets.\\n    optimizer (torch.optim.Optimizer): Optimizer used to update the model.\\n    device (torch.device): Device on which computations occur.\\n    metrics_list (list, optional): List of metric names to compute; defaults to ['accuracy']. \\n\\nReturns:\\n    dict: Metric names mapped to their computed float values.\\n\\nRaises:\\n    RuntimeError: If there is an error during the training step.\"},\n",
       " {'name': 'train_mlflow',\n",
       "  'docstring': 'Train a model with MLflow tracking.\\n\\nArgs:\\n    model (torch.nn.Module): The model to train.\\n    train_loader (DataLoader): DataLoader yielding input tensors and target labels for training.\\n    val_loader (DataLoader): DataLoader yielding input tensors and target labels for validation.\\n    optimizer (torch.optim.Optimizer): Optimizer used to update the model.\\n    loss_fn (callable): Callable that computes the loss between model outputs and targets.\\n    cfg (dict): Configuration dictionary.\\n    device (torch.device, optional): Device on which computations occur; defaults to None.\\n    continue_training (bool, optional): Whether to continue training from a previous checkpoint; defaults to False.\\n    continue_path (str, optional): Path to the previous checkpoint; defaults to None.\\n    prev_metrics (dict, optional): Previous metrics; defaults to None.\\n\\nReturns:\\n    dict: Training results.'},\n",
       " {'name': '__init__',\n",
       "  'docstring': 'Initializes an EarlyStopping monitor that stops training when a monitored metric does not improve for a specified number of epochs.\\n\\nArgs:\\n    patience (int): Number of epochs with no improvement to tolerate.\\n    verbose (bool): Whether to print messages when no improvement is observed.\\n    delta (float): Minimum change to qualify as an improvement.'},\n",
       " {'name': '__call__',\n",
       "  'docstring': 'Call the EarlyStopping monitor.\\n\\nArgs:\\n    val_loss (float): Validation loss.'}]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ba92c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for func_data in suggested:\n",
    "  update_docstring(file_path_0, func_data=func_data )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
