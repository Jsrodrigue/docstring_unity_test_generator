{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4d44af",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d5ae87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API KEYS\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "# API Urls\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# Client instances\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "groq_client = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "\n",
    "# Clients dictionary with models\n",
    "clients = {\n",
    "    \"gpt-4o-mini\": openai_client,          # OpenAI model\n",
    "    \"llama-3.1-8b-instant\": groq_client,   # Groq cheap model for testing\n",
    "    \"gpt-oss-20b\": groq_client,            # Groq GPT OSS 20B\n",
    "    \"openai/gpt-oss-120b\": groq_client     # Groq GPT OSS 120B powerful\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Python expert. Generate Python docstrings following best practices updated in 2025:\n",
    "- Use triple double quotes (\\\"\\\"\\\") for the docstring.\n",
    "- Include a brief description of what the function does.\n",
    "- Include Args with type annotations and descriptions.\n",
    "- Include Returns with type and description if applicable.\n",
    "- Include Raises if the function can raise exceptions.\n",
    "- Keep lines <= 79 characters.\n",
    "- ONLY return the docstring text using triple double quotes, do NOT add explanations, \n",
    "  comments, code, or anything else.\n",
    "- Do NOT include Markdown syntax (e.g., ```python) or any code formatting.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt base template\n",
    "PROMPT_TEMPLATE = \"\"\"Write or improve the Python docstring for the following function.\n",
    "- If the function already has a docstring, improve it following best practices.\n",
    "- If it has no docstring, generate a new one. \n",
    "- Include description of what it does and its arguments.\n",
    "- Return ONLY the docstring using triple double quotes (\\\"\\\"\\\").\n",
    "- Do NOT add explanations, comments, or code blocks.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d70559",
   "metadata": {},
   "source": [
    "# STEP 1: Extract the functions info from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "#############################################################################\n",
    "# Function to extract the info of the functons from the path of a python file \n",
    "#############################################################################\n",
    "\n",
    "def extract_functions(file_path):\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    # Parse the code into an Abstract Syntax Tree (AST)\n",
    "    tree = ast.parse(code)\n",
    "\n",
    "    funcs = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            # Extract data of each function\n",
    "            func_info = {\n",
    "                \"name\": node.name,\n",
    "                \"args\": [arg.arg for arg in node.args.args],\n",
    "                \"docstring\": ast.get_docstring(node),\n",
    "                \"source\": ast.get_source_segment(code, node)\n",
    "            }\n",
    "            funcs.append(func_info)\n",
    "\n",
    "    return funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24441921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Name: greet\n",
      "   Arguments: ['name']\n",
      "   Docstring: Return a greeting message\n",
      "   Source: def greet(name):\n",
      "    \"\"\"Return a greeting message\"\"\"\n",
      "    return f'Hello, {name}!'\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ”¹ Name: add\n",
      "   Arguments: ['a', 'b']\n",
      "   Docstring: None\n",
      "   Source: def add(a, b):\n",
      "    return a + b\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ”¹ Name: multiply\n",
      "   Arguments: ['a', 'b', 'c']\n",
      "   Docstring: Multiplies three numbers\n",
      "   Source: def multiply(a, b, c=1):\n",
      "    \"\"\"Multiplies three numbers\"\"\"\n",
      "    return a * b * c\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"examples/example.py\" \n",
    "\n",
    "functions = extract_functions(file_path)\n",
    "\n",
    "for func in functions:\n",
    "    print(f\"\\nðŸ”¹ Name: {func['name']}\")\n",
    "    print(f\"   Arguments: {func['args']}\")\n",
    "    print(f\"   Docstring: {func['docstring']}\")\n",
    "    print(f\"   Source: {func['source']}\")\n",
    "\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b329d4a",
   "metadata": {},
   "source": [
    "# STEP 2: Generate docstring with openai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Function to generate docstring\n",
    "##################################\n",
    "\n",
    "def generate_docstring_from_source(\n",
    "    func_source, \n",
    "    model=\"llama-3.1-8b-instant\", \n",
    "    backend=\"openai\",\n",
    "    prompt_template=None,\n",
    "    system_prompt=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a Python docstring for a given function source code using an LLM.\n",
    "\n",
    "    Args:\n",
    "        func_source: str, the full source code of the function\n",
    "        model: str, name of the model to use\n",
    "        backend: str, \"openai\" or \"groq\"\n",
    "        prompt_template: str, base user prompt to prepend before the function code\n",
    "        system_prompt: str, system prompt to guide the LLM behavior\n",
    "\n",
    "    Returns:\n",
    "        str: generated docstring\n",
    "    \"\"\"\n",
    "    if prompt_template is None:\n",
    "        raise ValueError(\"prompt_template must be provided\")\n",
    "    if system_prompt is None:\n",
    "        raise ValueError(\"system_prompt must be provided\")\n",
    "\n",
    "    prompt = prompt_template + \"\\nFunction:\\n\" + func_source\n",
    "\n",
    "    if backend not in [\"openai\", \"groq\"]:\n",
    "        raise ValueError(f\"Unknown backend: {backend}\")\n",
    "    \n",
    "    if model not in clients:\n",
    "        raise ValueError(f\"Model '{model}' not found in clients dictionary.\")\n",
    "    \n",
    "    client = clients[model]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76518771",
   "metadata": {},
   "outputs": [],
   "source": [
    "docstring = generate_docstring_from_source(\n",
    "    func_source=functions[1]['source'], \n",
    "    model=\"llama-3.1-8b-instant\", \n",
    "    backend=\"openai\",\n",
    "    prompt_template=PROMPT_TEMPLATE,\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee5efdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "Adds two numbers together.\n",
      "\n",
      "Args:\n",
      "    a (int or float): The first number to be added.\n",
      "    b (int or float): The second number to be added.\n",
      "\n",
      "Returns:\n",
      "    int or float: The result of adding a and b together.\n",
      "\n",
      "Raises:\n",
      "    TypeError: If a or b are not numeric.\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "print(docstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b90b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
