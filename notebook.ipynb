{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4d44af",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ae87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load API KEYS\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "# API Urls\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "\n",
    "# Client instances\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "groq_client = OpenAI(api_key=groq_api_key, base_url=groq_url)\n",
    "\n",
    "# Clients dictionary with models\n",
    "clients = {\n",
    "    \"gpt-4o-mini\": openai_client,                                   # OpenAI model\n",
    "    \"meta-llama/llama-4-scout-17b-16e-instruct\" : groq_client,      # Groq cheap model for testing\n",
    "    \"openai/gpt-oss-20b\": groq_client,                              # Groq GPT OSS 20B\n",
    "    \"openai/gpt-oss-120b\": groq_client                              # Groq GPT OSS 120B powerful\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2ab1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt \n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a Python expert. Generate Python docstrings following best practices updated in 2025:\n",
    "- Include a brief description of what the function does.\n",
    "- Include Args with type annotations and descriptions.\n",
    "- Include Returns with type and description if applicable.\n",
    "- Include Raises if the function can raise exceptions.\n",
    "- Keep lines <= 79 characters.\n",
    "- ONLY return the docstring text, without triple quotes or any additional formatting.\n",
    "- Correct any formatting errors in existing docstrings.\n",
    "- Do NOT add explanations, comments, code, or anything else.\n",
    "- Do NOT include Markdown syntax (e.g., ```python) or any code formatting.\n",
    "- Write all the docstring in English.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt base template\n",
    "PROMPT_TEMPLATE = \"\"\"Write or improve the Python docstring for the following function.\n",
    "- If the function already has a docstring, improve it following best practices.\n",
    "- If it has no docstring, generate a new one.\n",
    "- Process the code exactly as provided.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d70559",
   "metadata": {},
   "source": [
    "# STEP 1: Extract the functions info from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "#############################################################################\n",
    "# Function to extract the info of the functons from the path of a python file \n",
    "#############################################################################\n",
    "\n",
    "def extract_functions(file_path):\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    # Parse the code into an Abstract Syntax Tree (AST)\n",
    "    tree = ast.parse(code)\n",
    "\n",
    "    funcs = []\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            # Extract data of each function\n",
    "            func_info = {\n",
    "                \"name\": node.name,\n",
    "                \"args\": [arg.arg for arg in node.args.args],\n",
    "                \"docstring\": ast.get_docstring(node),\n",
    "                \"source\": ast.get_source_segment(code, node)\n",
    "            }\n",
    "            funcs.append(func_info)\n",
    "\n",
    "    return funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24441921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Name: greet\n",
      "   Arguments: ['name']\n",
      "   Docstring: Return a greeting message\n",
      "   Source: def greet(name):\n",
      "    \"\"\"Return a greeting message\"\"\"\n",
      "    return f'Hello, {name}!'\n",
      "--------------------------------------------------\n",
      "\n",
      "üîπ Name: add\n",
      "   Arguments: ['a', 'b']\n",
      "   Docstring: None\n",
      "   Source: def add(a, b):\n",
      "    return a + b\n",
      "--------------------------------------------------\n",
      "\n",
      "üîπ Name: multiply\n",
      "   Arguments: ['a', 'b', 'c']\n",
      "   Docstring: Multiplies three numbers\n",
      "   Source: def multiply(a, b, c=1):\n",
      "    \"\"\"Multiplies three numbers\"\"\"\n",
      "    return a * b * c\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"examples/example.py\" \n",
    "\n",
    "functions = extract_functions(file_path)\n",
    "\n",
    "for func in functions:\n",
    "    print(f\"\\nüîπ Name: {func['name']}\")\n",
    "    print(f\"   Arguments: {func['args']}\")\n",
    "    print(f\"   Docstring: {func['docstring']}\")\n",
    "    print(f\"   Source: {func['source']}\")\n",
    "\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b329d4a",
   "metadata": {},
   "source": [
    "# STEP 2: Generate docstring with openai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "446c43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Function to generate docstring\n",
    "##################################\n",
    "\n",
    "def generate_docstring_from_source(\n",
    "    func_source, \n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\", \n",
    "    prompt_template=None,\n",
    "    system_prompt=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a Python docstring for a given function source code using an LLM.\n",
    "\n",
    "    Args:\n",
    "        func_source: str, the full source code of the function\n",
    "        model: str, name of the model to use\n",
    "        backend: str, \"openai\" or \"groq\"\n",
    "        prompt_template: str, base user prompt to prepend before the function code\n",
    "        system_prompt: str, system prompt to guide the LLM behavior\n",
    "\n",
    "    Returns:\n",
    "        str: generated docstring\n",
    "    \"\"\"\n",
    "    if prompt_template is None:\n",
    "        raise ValueError(\"prompt_template must be provided\")\n",
    "    if system_prompt is None:\n",
    "        raise ValueError(\"system_prompt must be provided\")\n",
    "\n",
    "    prompt = prompt_template + \"\\nFunction:\\n\" + func_source\n",
    "    \n",
    "    if model not in clients:\n",
    "        raise ValueError(f\"Model '{model}' not found in clients dictionary.\")\n",
    "    \n",
    "    client = clients[model]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=200\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "76518771",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggested_docstring = generate_docstring_from_source(\n",
    "    func_source=functions[0]['source'], \n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\", \n",
    "    prompt_template=PROMPT_TEMPLATE,\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee5efdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Returns a personalized greeting message.\\n\\nArgs:\\n    name (str): The name of the person to be greeted. \\n                Cannot be empty.\\n\\nReturns:\\n    str: A greeting message with the name inserted, \\n         formatted as 'Hello, <name>!'.\\n\\nRaises:\\n    TypeError: If the input 'name' is not a string.\\n    ValueError: If the input 'name' is an empty string.\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggested_docstring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d531e",
   "metadata": {},
   "source": [
    "# STEP 3: Compare and write docstring in the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15b90b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_docstring_in_file(file_path, func_name, new_docstring):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        code = f.read()\n",
    "\n",
    "    tree = ast.parse(code)\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.FunctionDef) and node.name == func_name:\n",
    "            doc_node = ast.Expr(value=ast.Constant(value=new_docstring))\n",
    "            \n",
    "            if ast.get_docstring(node):  # si ya tiene docstring\n",
    "                node.body[0] = doc_node\n",
    "            else:  # si no tiene docstring, insertar al inicio\n",
    "                node.body.insert(0, doc_node)\n",
    "\n",
    "    # convertir AST a c√≥digo\n",
    "    new_code = astor.to_source(tree)\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(new_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd73f5",
   "metadata": {},
   "source": [
    "# STEP 4: Test the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bdbdd872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original source: \n",
      " def add(a, b):\n",
      "    return a + b\n",
      "Suggested docstring: Add two numbers.\n",
      "\n",
      "Args:\n",
      "    a (int or float): The first number to add.\n",
      "    b (int or float): The second number to add.\n",
      "\n",
      "Returns:\n",
      "    int or float: The sum of a and b.\n",
      "New source: \n",
      " def add(a, b):\n",
      "    \"\"\"Add two numbers.\n",
      "\n",
      "Args:\n",
      "    a (int or float): The first number to add.\n",
      "    b (int or float): The second number to add.\n",
      "\n",
      "Returns:\n",
      "    int or float: The sum of a and b.\"\"\"\n",
      "    return a + b\n"
     ]
    }
   ],
   "source": [
    "file_path = \"examples/example.py\"\n",
    "# Extract the first function\n",
    "functions = extract_functions(file_path)\n",
    "func = functions[1]\n",
    "\n",
    "# Print original source\n",
    "print(f\"Original source: \\n {func[\"source\"]}\")\n",
    "\n",
    "#Suggest docstring  \n",
    "suggested_docstring = generate_docstring_from_source(func['source'], \n",
    "                                                     prompt_template=PROMPT_TEMPLATE, \n",
    "                                                     system_prompt=SYSTEM_PROMPT,\n",
    "                                                     model=\"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "                                                     )\n",
    "print(f\"Suggested docstring: {suggested_docstring}\")\n",
    "update_docstring_in_file(file_path, func['name'], suggested_docstring)\n",
    "\n",
    "# Print modified source\n",
    "functions = extract_functions(file_path)\n",
    "func = functions[1]\n",
    "print(f\"New source: \\n {func[\"source\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0500eb29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
